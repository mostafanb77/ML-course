# ML-course

This repository contains four mini projects completed for the classes taught by Dr. Aliyari at KNTU. Each project focuses on different aspects of machine learning and reinforcement learning, ranging from binary classification and least squares methods to neural networks, support vector machines, and reinforcement learning.
## Project Overview
### MP1: Binary Classification and Least Squares Methods
This project addresses three main questions:

#### Binary Classification:
Developing a binary classification model to classify data into two categories.
#### Fault Detection:
Applying binary classification for fault detection in systems.
#### Least Squares Methods:
Implementing and comparing Least Squares (LS), Recursive Least Squares (RLS), and Weighted Least Squares (WLS) methods.
### MP2: Neural Networks and Decision Trees
This project explores various algorithms for classification:

#### Multilayer Perceptron (MLP):
A class of feedforward artificial neural network (ANN) consisting of at least three layers of nodes.
#### Perceptron: 
An artificial neural network unit that detects features or business intelligence in the input data.
#### Decision Tree:
A flowchart-like structure where each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label.
#### Bayes Algorithm:
A statistical classification method based on Bayes' theorem.


### MP3: Support Vector Machines, Denoising Autoencoder, and Classification
This project focuses on implementing and comparing:

#### Support Vector Machines (SVM):
Support Vector Machines (SVM) are supervised learning models used for classification and regression analysis. They work by finding the hyperplane that best separates different classes in the feature space, maximizing the margin between the closest points of the classes (support vectors).


#### Denoising Autoencoder (DAE):
A Denoising Autoencoder (DAE) is a type of neural network used to learn efficient codings of input data by intentionally corrupting the input and training the model to reconstruct the original, noise-free data. This helps in learning robust features and improving data representation.


#### Classification algorithms:
Classification algorithms are supervised learning methods used to predict the categorical label of new observations based on past observations. Common classification algorithms include Decision Trees, Naive Bayes, and Neural Networks, each utilizing different techniques to map input features to discrete output labels.

### MP4: Reinforcement Learning
This project focuses on reinforcement learning in a grid-based environment, implementing the following algorithms:

#### Q-Learning: 
An off-policy algorithm to learn the optimal policy directly using an epsilon-greedy policy for exploration and exploitation balance.
#### Deep Q-Network (DQN): 
A neural network that approximates Q-values using replay memory for training stability.
#### Environment Details
##### GridEnvironment class: 
Includes grid layout, agent starting position, goal, pits, Wumpus, and actions.
##### Rewards: +100 for finding gold, -1000 for falling into pits or encountering Wumpus, +50 for shooting Wumpus, -1 for movement.
#### Comparison of Q-Learning and DQN
##### Cumulative Rewards: Plot to visualize performance over episodes.
##### Average Reward per Episode: Comparison after 1000 episodes to evaluate algorithm effectiveness.



## Contact
For any questions or comments, please contact us at:

mostafa.nabipour1@gmail.com
